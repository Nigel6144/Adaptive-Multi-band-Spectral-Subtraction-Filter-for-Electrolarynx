# Electrolarynx Speech Enhancement

A hardware implementation of an electrolarynx speech enhancement filter deployed on the Zynq-7000 SoC using **minimum-statistics** adaptive noise estimation together with **multi-band spectral subtraction**. The script reduces device-induced buzzing and background noise while preserving important speech characteristics by applying different subtraction factors across frequency bands.

---

## Files

- `electrolarynx_filter_ps.c` — Main C script .
- `input.wav` — Example noisy recording (place your input in the sd card formatted in Fat32 format).
- `electrolarynx_enhanced.wav` — Output generated by the script in the sd card
- `hardware implmentaion.md` — This file.
- Note:
  - Rename your script file to `electrolarynx_filter_ps.c` or modify usage instructions accordingly.
  - Use AMD Vitis Classic not AMD Vitis Unified Platform
  - Max lenght of audio file is 8 chacters Long


## Folder Access
- TO ACCESS THE PROJECT FOLDER CLICK ON THIS LINK:
  https://drive.google.com/drive/folders/1ZBnOQJu7pwbS7r5lpNrQUE1H33QCisqD?usp=sharing


---

## Quick description

The algorithm performs the following steps:
1. Read the noisy electrolarynx audio file and compute the STFT.
2. Estimate the noise in each frequency bin using **minimum-statistics** tracking.
3. Perform **multi-band spectral subtraction**: partition the spectrum into frequency bands and apply band-specific over-subtraction factors to remove noise while retaining speech cues.
4. Reconstruct the enhanced signal using the original phase and inverse STFT, normalize and save the result.

---

## Requirements

- AMD Vitis classic ( I used AMD Vitis 2024.2 )
- AMD Vivado(Ver.2024.2).
- SD Card ( Fat32 formatted and audio file in .wav format)
  

## How to run
### AMD Vivado Block Design
- Create the Vivado Project
- Generate the Block design and add Zynq7000 Processing System IP
- Run Block Automation
- Enable SD interface on the Zynq70000 PS IP
- Connect the Clocking wizard IP 
- Run Synthesis → Implementation → Generate Bitstream
-Export the Hardware Platform(.XSA File)

### Running the code on PS using AMD Vitis Classic
- Create platform from the hardware .XSA file
- Enable Fatfs in Vitis to enable sd card interfacing
- Run the C Code
- View the various operations using the Serial monitor for a baud rate of 115200
 
## Important parameters (in-script)

### Memory / storage

-DDR_BASE_ADDR: base DDR address used when reading/writing WAV data.

-DDR_PROC_ADDR: start address in DDR reserved for all processing buffers (input/output, FFT, frames).

-DDR_MEMORY_SIZE: size (bytes) of the DDR region reserved for processing.

-MAX_FILE_SIZE: maximum allowed input audio data size (bytes) to avoid trying to load very large files.

-MAX_AUDIO_SAMPLES: safety limit on number of audio samples the algorithm will accept/process.

### File I/O / WAV assumptions

-input filename ("input.wav"): default input WAV file name the program expects on the SD card.

-output filename ("output.wav"): default name used to write the enhanced audio back to the SD card.

-WAV format assumptions: expects 16-bit PCM WAV that is single channel, reads first channel only for multi channel audio files .

### STFT / frame processing

-FRAME_LEN: number of time-domain samples per analysis frame (window length).

-OVERLAP: number of overlapping samples between consecutive frames.

-HOP_SIZE: frame hop (FRAME_LEN − OVERLAP); the advance between consecutive frames.

-NFFT: FFT size used for forward/inverse transforms (must be ≥ FRAME_LEN and a power of two).

-SAMPLE_RATE: default sample rate used is 44.1kHz unless overridden by input WAV header.

-MAX_FRAMES: maximum number of STFT frames supported to avoid overload.

### Noise estimation & spectral subtraction

-MIN_WIN: number of frames used by the minimum-statistics noise tracker to form the initial noise spectrum.

-LAMBDA_D: smoothing factor for the adaptive noise estimate (closer to 1 = slower adaptation and vice versa).

-SPECTRAL_FLOOR: relative spectral floor to prevent negative/very small magnitudes after subtraction.

### Multi-band parameters

-NUM_BANDS: number of frequency bands used for band-specific subtraction.

-alpha_factors[] — per-band subtraction scaling (higher = more aggressive noise reduction for that band), tune according to   your speech charactertics

---

## How it works (brief)
- SD Card Input WAV File: Reads the noisy speech signal stored as a WAV file 
from the SD card into the system for processing.

- Memory Pool DDR 64MB: Allocates a 64 MB memory pool in DDR for 
  buffering and intermediate storage of audio data during processing.

- Audio Context Initialization: Initializes the audio processing context, setting 
  up parameters and configurations required for subsequent operations. 

- Streaming Processor: Sets up a streaming processor to handle real-time audio 
  data flow for continuous processing. 

- STFT Analysis: Applies Short-Time Fourier Transform (STFT) to divide the 
  audio signal into small frames and convert it into the frequency domain for 
  noise analysis and processing. 

- Noise Estimation: Estimates the background noise present in the signal using 
  statistical analysis techniques. 

- Spectral Subtraction: Performs noise suppression by subtracting the estimated 
  noise spectrum from the noisy speech spectrum to enhance the speech quality. 

- IFFT Synthesis: Applies Inverse Fast Fourier Transform (IFFT) to convert the 
  processed frequency-domain data back into a time-domain signal.

- SD Card Output Enhanced WAV: Saves the enhanced speech signal as a WAV 
  file back to the SD card for playback or further use.

This combination aims to suppress the electrolarynx buzzing while preserving intelligibility and naturalness.

---

## Evaluation

You can evaluate enhancement performance using objective metrics such as:

- **DNSMOS** (Deep Noise Supression Mean Opinion Score)
- **PESQ** (Perceptual Evaluation of Speech Quality)
- **STOI** (Short-Time Objective Intelligibility)
- **SNR** (Energy-based SNR before/after)

Community implementations for PESQ/STOI exist in Python and MATLAB — add reference clean/noisy files and run evaluation scripts to generate numbers and plots. Save results to a `results/` folder and include example audio for subjective listening tests.

---

## Tuning tips

- Start with conservative alpha values (close to 1) and vary only for bands where the buzzing persists.
- Tune `min_win` and `lambda_D` to match the dynamics of your recording: longer `min_win` for slowly varying buzz, smaller     for quick changes.
- Visualize spectrograms of noisy vs enhanced audio to inspect which bands still contain device noise.
- If musical/tonal buzzing remains, adjust the lambda values.
- Change the frequency bands of the audio file based on your electrolarynx speech frequency.
- Vary the subtraction factors accordingly.

---

## Real-time & embedded considerations

- Current implementation involves using processing system of the Zynq-7000 for computation and loading entire audio file to    the RAM. To improve further
  - Use IP blocks such as FFT and IFFT in Vivado to offload compute to PL to enable parallel processing and meet real-time       latency requirements. 
  - Use optimized FFT and IFFT libaries such as ARM CMSIS DSP Library, FFTW (Fast Fourier Transform in the West) for             implentation in the Processing System(PS) though integrating it can be a challenging task.
  - Reduce Memory requirement on the RAM by using audio streaming to RAM .
  - Utilize AXI-DMA to Tranfer audio samples from DDR to PL.

---

## Caveats & known issues

- Over-aggressive subtraction causes musical noise artifacts or speech distortion. Carefully balance `alpha_factors` for perceptual quality.
- Phase is preserved from the noisy signal; advanced phase reconstruction methods (e.g., iterative Griffin–Lim variants) may further improve naturalness but add complexity.


---

## Contact / Acknowledgements

If you found this helpful or want to collaborate, open an issue or PR — or contact the repository owner.



