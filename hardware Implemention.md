# Electrolarynx Speech Enhancement

A hardware implementation of an electrolarynx speech enhancement filter deployed on the Zynq-7000 SoC using **minimum-statistics** adaptive noise estimation together with **multi-band spectral subtraction**. The script reduces device-induced buzzing and background noise while preserving important speech characteristics by applying different subtraction factors across frequency bands.

---

## Files

- `electrolarynx_filter_ps.c` — Main MATLAB script .
- `electrolarynx_noisy_audio.wav` — Example noisy recording (place your input in the sd card formatted in Fat32 format).
- `electrolarynx_enhanced.wav` — Output generated by the script in the sd card
- `hardware implmentaion.md` — This file.
- Note: rename your script file to `electrolarynx_filter_ps.c` or modify usage instructions accordingly.


## Folder Access
- TO ACCESS THE FOLDER CLICK ON THIS LINK:
  https://drive.google.com/drive/folders/1ZBnOQJu7pwbS7r5lpNrQUE1H33QCisqD?usp=sharing


---

## Quick description

The algorithm performs the following steps:
1. Read the noisy electrolarynx audio file and compute the STFT.
2. Estimate the noise in each frequency bin using **minimum-statistics** tracking.
3. Perform **multi-band spectral subtraction**: partition the spectrum into frequency bands and apply band-specific over-subtraction factors to remove noise while retaining speech cues.
4. Reconstruct the enhanced signal using the original phase and inverse STFT, normalize and save the result.

---

## Requirements

- AMD Vitis classic ( I used AMD Vitis 2024.2 )
- AMD Vivado(Ver.2024.2).
- SD Card ( Fat32 formatted and audio file in .wav format)
- 

## How to run

1. Place your noisy WAV file in the working directory and name it `electrolarynx_noisy_audio.wav` (or change the filename in the script).
2. Open MATLAB and run the script :
   For example

```matlab
electrolarynx_filter.m
```

3. The script writes the enhanced waveform to `electrolarynx_enhanced.wav` and plays it back.

---

## Important parameters (in-script)

- `frame_len` — STFT frame length in samples (default `64`). Smaller frames reduce latency but may reduce spectral resolution.
- `overlap` — Overlap length between frames (default 32). Typical values are 50% of `frame_len`.
- `nfft` — FFT length (default `512`). Choose >= `frame_len` for good spectral resolution.
- `lambda_D` — Smoothing factor for noise tracking (default `0.85`). Higher values give slower adaptation while lower values introduce a musical artifact effect.
- `min_win` — Minimum-statistics window length (frames) used to find local minima for noise (default `15`). Larger windows produce more conservative noise estimates.
- `freq_bands` — Frequency band edges in Hz. Default in the script: `[0, 300, 1000, 2000, 3000, 5000, fs/2]`.
- `alpha_factors` — Over-subtraction factor for each band (vector). Larger values remove more noise but may increase speech distortion. The default example uses `[1, 1.3, 1.6, 100, 100]` — **these extreme values may be placeholders**; tune them for your recordings.

---

## How it works (brief)
- SD Card Input WAV File: Reads the noisy speech signal stored as a WAV file 
from the SD card into the system for processing.

- Memory Pool DDR 64MB: Allocates a 64 MB memory pool in DDR for 
  buffering and intermediate storage of audio data during processing.

- Audio Context Initialization: Initializes the audio processing context, setting 
  up parameters and configurations required for subsequent operations. 

- Streaming Processor: Sets up a streaming processor to handle real-time audio 
  data flow for continuous processing. 

- STFT Analysis: Applies Short-Time Fourier Transform (STFT) to divide the 
  audio signal into small frames and convert it into the frequency domain for 
  noise analysis and processing. 

- Noise Estimation: Estimates the background noise present in the signal using 
  statistical analysis techniques. 

- Spectral Subtraction: Performs noise suppression by subtracting the estimated 
  noise spectrum from the noisy speech spectrum to enhance the speech quality. 

- IFFT Synthesis: Applies Inverse Fast Fourier Transform (IFFT) to convert the 
  processed frequency-domain data back into a time-domain signal.

- SD Card Output Enhanced WAV: Saves the enhanced speech signal as a WAV 
  file back to the SD card for playback or further use.

This combination aims to suppress the electrolarynx buzzing while preserving intelligibility and naturalness.

---

## Evaluation

You can evaluate enhancement performance using objective metrics such as:

- **DNSMOS** (Deep Noise Supression Mean Opinion Score)
- **PESQ** (Perceptual Evaluation of Speech Quality)
- **STOI** (Short-Time Objective Intelligibility)
- **SNR** (Energy-based SNR before/after)

Community implementations for PESQ/STOI exist in Python and MATLAB — add reference clean/noisy files and run evaluation scripts to generate numbers and plots. Save results to a `results/` folder and include example audio for subjective listening tests.

---

## Tuning tips

- Start with conservative alpha values (close to 1) and vary only for bands where the buzzing persists.
- Tune `min_win` and `lambda_D` to match the dynamics of your recording: longer `min_win` for slowly varying buzz, smaller     for quick changes.
- Visualize spectrograms of noisy vs enhanced audio to inspect which bands still contain device noise.
- If musical/tonal buzzing remains, adjust the lambda values.
- Change the frequency bands of the audio file based on your electrolarynx speech frequency.
- Vary the subtraction factors accordingly.

---

## Real-time & embedded considerations

- Current implementation involves using processing system of the Zynq-7000 for computation and loading entire audio file to    the RAM. To improve further
  - Use IP blocks such as FFT and IFFT in Vivado to offload compute to PL to enable parallel processing and meet real-time       latency requirements. 
  - Use optimized FFT and IFFT libaries such as ARM CMSIS DSP Library, FFTW (Fast Fourier Transform in the West) for             implentation in the Processing System(PS) though integrating it can be a challenging task.
  - Reduce Memory requirement on the RAM by using audio streaming to RAM .
  - Utilize AXI-DMA to Tranfer audio samples from DDR to PL.

---

## Caveats & known issues

- Over-aggressive subtraction causes musical noise artifacts or speech distortion. Carefully balance `alpha_factors` for perceptual quality.
- Phase is preserved from the noisy signal; advanced phase reconstruction methods (e.g., iterative Griffin–Lim variants) may further improve naturalness but add complexity.


---

## Contact / Acknowledgements

If you found this helpful or want to collaborate, open an issue or PR — or contact the repository owner.



